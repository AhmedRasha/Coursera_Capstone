{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Severity of Car Accident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content  \n",
    "[1. Introduction: Problem Understanding](#problem)  \n",
    "[2. Data](#data)  \n",
    "> [2.1. Data Understanding](#datUnd)  \n",
    "  [2.2. Data Wrangling](#datWrang)\n",
    "\n",
    "[3. Methodolgy](#method)  \n",
    "> [3.1. Exploratory Data Analysis](#exp)  \n",
    "  [3.2. Feature Selection and Feature Engineering](#feature)  \n",
    "  [3.3. Modeling](#model)  \n",
    "  [3.4. Model Evaluation](#eval)  \n",
    "  \n",
    "[4. Results and Discussion](#rd)  \n",
    "[5. Conclusion](#conc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction: Problem Understanding <a class=\"anchor\" id=\"problem\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would it not be great if you could tell in advance how sever an accident will be if it occurs?! In this project, we will use a car-accident data of the in the <font color=\"red\"> Seatle city  in the Washington State, US </font> from 2004 to 2013. The data\n",
    "\n",
    "At the end of this project, you should be able to tell how sever a collision is based on some attributes of the collision such as the street at which it occurs, weather condition, light condition, whether the driver was under the influence of alcohol or drug, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Understanding <a class=\"anchor\" id=\"datUnd\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains information about the car accidents occured in the Seattle city in the US  The data contains 221144 records and 40 attributes (features) which include the severity, coordinates, location of the accident, weather and light condition, wether the accident is due to speeding or under the influence of of alcohol. The data has a public open access and can be downloaded from the [city goverment website](https://data.seattle.gov/).\n",
    "\n",
    "The features of the data are summarized in the following table:  \n",
    "\n",
    "| Feature/Attribute | Description |\n",
    "| :- | :- |\n",
    "| SEVERITYCODE | A code that corresponds to the severity of the collision. **This is the target label** |\n",
    "| X | The x-coordinate of the exact location of the collision |\n",
    "| Y | The y-coordinate of the exact location of the collision |\n",
    "| ObjectID | Unique identifier |\n",
    "| INCKEY | A unique key for the incident |\n",
    "| COLDETKEY | Secondary key for the incident |\n",
    "| STATUS | NA |\n",
    "| ADDRTYPE | Collision address type which can be _alley, block_ or _intersection_ |\n",
    "| INTKEY | Key that corresponds to the intersection associated with a collision |\n",
    "| LOCATION | Description of the general location of the collision |\n",
    "| EXCEPTRSNCODE | NA |\n",
    "| EXCEPTRSNDESC | NA |\n",
    "| SEVERITYDESC | A detailed description of the severity of the collision |\n",
    "| COLLISIONTYPE | Collision type |\n",
    "| PERSONCOUNT | The total number of people involved in the collision |\n",
    "| FATALITIES | The number of fatalities in the collision. This is entered by the state |\n",
    "| INCDATE | The date of the incident |\n",
    "| INCDTTM | The date and time of the incident |\n",
    "| JUNCTIONTYPE | Category of junction at which collision took place |\n",
    "| SDOT_COLCODE | A code given to the collision by SDOT |\n",
    "| SDOT_COLDESC | A description of the collision corresponding to the collision code |\n",
    "| INATTENTIONIND | Whether or not collision was due to inattention |\n",
    "| UNDERINFL | Whether or not a driver involved was under the influence of drugs or alcohol |\n",
    "| WEATHER | A description of the weather conditions during the time of the collision |\n",
    "| ROADCOND | The condition of the road during the collision |\n",
    "| LIGHTCOND | The light conditions during the collision |\n",
    "| PEDROWNOTGRNT | Whether or not the pedestrian right of way was not granted |\n",
    "| SDOTCOLNUM | A number given to the collision by SDOT |\n",
    "| SPEEDING | Whether or not speeding was a factor in the collision |\n",
    "| ST_COLCODE | A code provided by the state that describes the collision |\n",
    "| ST_COLDESC | A description that corresponds to the stateâ€™s coding designation |\n",
    "| SEGLANEKEY | A key for the lane segment in which the collision occurred |\n",
    "| CROSSWALKKEY | A key for the crosswalk at which the collision occurred |\n",
    "| HITPARKEDCAR | Whether or not the collision involved hitting a parked car |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**  \n",
    "- The target label `SEVERITYCODE` has multiple values. Therefore, we have a <font color=\"red\"> multiclass classification </font> problem.\n",
    "- The target label takes the following values:\n",
    "\n",
    "| Value | Description |\n",
    "| :- | :- |\n",
    "| 0 | Unknown |\n",
    "| 1 | Property damage |\n",
    "| 2 | Injury |\n",
    "| 2b | Serious Injury |\n",
    "| 3 | Fatality |\n",
    "\n",
    "- The values of the target label are not equally represented in the dataset. Therefore, we have <font color=\"red\"> imbalance classification </font> problem.  \n",
    "- Not of all attributes are relevant for modeling such as various keys that are probably used to archiving and administrative purposes such as `OBJECTID` (a key for uniquely identifying collision), `REPORTNO` (a key for uniquely identifying the report of the collision), etc. These irrelevant attributes should be removed.\n",
    "- The remaining attributes, though relevant, correlate with different degrees to the severity of the accident and thus, we still perform feature selection to select the most informative features and to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"/home/ahmed/Courses/Data_Science/Capstone/Collisions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many features and observations we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observation = 221144 and number of features = 40\n"
     ]
    }
   ],
   "source": [
    "print('The number of observation = %d and number of features = %d' %(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, it can be observed that not all features are relevant for the machine learning model. These irrelevant features include several unique keys (OBJECTID, SDOT_COLCODE etc), the report number (REPORTNO), and description of the severity of the collision (SEVERITYDESC), etc.  \n",
    "\n",
    "Please note that not all keys should be removed since some keys are <font color=\"blue\"> informative </font> such as the intersection key (INTKEY) and lane key (SEGLANEKEY) which identify the intersection and the lane at which the collision occurs respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of possibly relevant feature = 25\n"
     ]
    }
   ],
   "source": [
    "df.drop(labels=['OBJECTID', 'EXCEPTRSNCODE', 'EXCEPTRSNDESC', 'INCDATE', 'INCDTTM', 'SDOT_COLCODE','SDOT_COLDESC',\\\n",
    "                'SDOTCOLNUM', 'ST_COLDESC', 'HITPARKEDCAR', 'INCKEY', 'COLDETKEY', 'REPORTNO', 'SEVERITYDESC',\\\n",
    "               'ST_COLCODE'], axis=1, inplace=True)\n",
    "# see how many attributes remaining\n",
    "print('The number of possibly relevant feature = %d' %(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X', 'Y', 'STATUS', 'ADDRTYPE', 'INTKEY', 'LOCATION',\n",
       "       'SEVERITYCODE', 'COLLISIONTYPE', 'PERSONCOUNT', 'PEDCOUNT',\n",
       "       'PEDCYLCOUNT', 'VEHCOUNT', 'INJURIES', 'SERIOUSINJURIES',\n",
       "       'FATALITIES', 'JUNCTIONTYPE', 'INATTENTIONIND', 'UNDERINFL',\n",
       "       'WEATHER', 'ROADCOND', 'LIGHTCOND', 'PEDROWNOTGRNT', 'SPEEDING',\n",
       "       'SEGLANEKEY', 'CROSSWALKKEY'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the feature names\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many classes and what is the distribution of these classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     137414\n",
       "2      58665\n",
       "0      21619\n",
       "2b      3096\n",
       "3        349\n",
       "Name: SEVERITYCODE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.SEVERITYCODE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> As can be observed the classes are not equally represented in the data set and thus, we have an </font> <font color=\"red\"> imbalanced classification. </font>. We will deal with this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data Wrangling <a class=\"anchor\" id=\"datWrang\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values are handled as follows:\n",
    "- Dropping a feature (dropping the entire column)  \n",
    "This is done when the missing values are too many (above 50%). In this case, imputing values will likely generate inaccurate data that does not represent the real distribution of the corresponding feature.\n",
    "- Droping a record (dropping the entire row)  \n",
    "This is done for missing values of the target label.\n",
    "- Replacing missing values with a roulette wheel selection  \n",
    "For categorical features, the common practice is to replace the missing values with the most frequent one. However, I come up with a better way of replacing the missing values that is more likely to respect the underlined, unknown distribution from which the data was drawn. This is done by a **roulette wheel selection** in which the probability of a non-missing value to replace a missing value is proportional to the frequency of the non-missing value.\n",
    "- Replace the missing value with the mean  \n",
    "Write sth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of the target label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the target label has missing values\n",
    "df.SEVERITYCODE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the missing value from the target label\n",
    "df.dropna(subset=['SEVERITYCODE'], axis=0, inplace=True)\n",
    "# reset the indexes\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# check again\n",
    "df.SEVERITYCODE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayna(dataFrame, threshold=50, showall=False):\n",
    "    \"\"\"\n",
    "    Print the columns that has missing values above a threshold. If showall is True, all columns will be displayed\n",
    "    regardless of the threshold.\n",
    "    \"\"\"\n",
    "    missing_data = dataFrame.isnull()\n",
    "    for column in missing_data.columns.values.tolist():    \n",
    "        series = missing_data[column].value_counts()\n",
    "        indexes = missing_data[column].value_counts().index.values.tolist()\n",
    "        printed = False\n",
    "        for idx in indexes:\n",
    "            if showall or (idx and np.round(100*series.loc[idx]/dataFrame.shape[0]) > threshold):\n",
    "                if(not printed): print(\"Column Name: \", column)\n",
    "                print(\"Missing Value? \", idx, \" Percentage: \", np.round(100*series.loc[idx]/dataFrame.shape[0]))\n",
    "                printed = True\n",
    "        if printed: print(\"\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling columns with too many missing values (above 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  INTKEY\n",
      "Missing Value?  True  Percentage:  68.0\n",
      "\n",
      "Column Name:  INATTENTIONIND\n",
      "Missing Value?  True  Percentage:  86.0\n",
      "\n",
      "Column Name:  PEDROWNOTGRNT\n",
      "Missing Value?  True  Percentage:  98.0\n",
      "\n",
      "Column Name:  SPEEDING\n",
      "Missing Value?  True  Percentage:  96.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of remaining features =  21\n"
     ]
    }
   ],
   "source": [
    "# drop those columns\n",
    "df.drop(labels=['INTKEY', 'INATTENTIONIND', 'PEDROWNOTGRNT', 'SPEEDING'], axis=1, inplace=True)\n",
    "# check\n",
    "print(\"The number of remaining features = \", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is any column with some missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  X\n",
      "Missing Value?  False  Percentage:  97.0\n",
      "Missing Value?  True  Percentage:  3.0\n",
      "\n",
      "Column Name:  Y\n",
      "Missing Value?  False  Percentage:  97.0\n",
      "Missing Value?  True  Percentage:  3.0\n",
      "\n",
      "Column Name:  STATUS\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  ADDRTYPE\n",
      "Missing Value?  False  Percentage:  98.0\n",
      "Missing Value?  True  Percentage:  2.0\n",
      "\n",
      "Column Name:  LOCATION\n",
      "Missing Value?  False  Percentage:  98.0\n",
      "Missing Value?  True  Percentage:  2.0\n",
      "\n",
      "Column Name:  SEVERITYCODE\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  COLLISIONTYPE\n",
      "Missing Value?  False  Percentage:  88.0\n",
      "Missing Value?  True  Percentage:  12.0\n",
      "\n",
      "Column Name:  PERSONCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  PEDCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  PEDCYLCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  VEHCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  INJURIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  SERIOUSINJURIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  FATALITIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  JUNCTIONTYPE\n",
      "Missing Value?  False  Percentage:  95.0\n",
      "Missing Value?  True  Percentage:  5.0\n",
      "\n",
      "Column Name:  UNDERINFL\n",
      "Missing Value?  False  Percentage:  88.0\n",
      "Missing Value?  True  Percentage:  12.0\n",
      "\n",
      "Column Name:  WEATHER\n",
      "Missing Value?  False  Percentage:  88.0\n",
      "Missing Value?  True  Percentage:  12.0\n",
      "\n",
      "Column Name:  ROADCOND\n",
      "Missing Value?  False  Percentage:  88.0\n",
      "Missing Value?  True  Percentage:  12.0\n",
      "\n",
      "Column Name:  LIGHTCOND\n",
      "Missing Value?  False  Percentage:  88.0\n",
      "Missing Value?  True  Percentage:  12.0\n",
      "\n",
      "Column Name:  SEGLANEKEY\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  CROSSWALKKEY\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayna(df, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider X and Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:**  \n",
    "\n",
    "Based on the result above, we can conclude that:  \n",
    "- Replacing a missing value with the mean does not make sense <font color=\"red\"> since the mean in this case can corrspond to a location in which it is impossible to have a car accident</font> such as a lake, stream, etc. \n",
    "- There is no dominant values for X and Y and the likelihood of having an accident at a particular (X,Y)-location is very small. Therefore, it makes sense to replace the missing values for X and Y by a randomly selected values from X and Y. \n",
    "\n",
    "Define a little function for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_replacena(dataFrame, col):\n",
    "    \"\"\"\n",
    "    Replace missing values with random values selected from the same series.\n",
    "    \"\"\"\n",
    "    # Find the non-missing values\n",
    "    series = dataFrame[pd.notna(dataFrame[col])][col]\n",
    "    # Replace missing values at random\n",
    "    dataFrame[col] = dataFrame[col].apply(lambda x: np.random.choice(series) if (pd.isna(x)) else x)\n",
    "    # Check if there is no missing value\n",
    "    if dataFrame[col].isna().sum() != 0:\n",
    "        print('Error!')\n",
    "    else:\n",
    "        print('Successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful!\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "random_replacena(df, 'X')\n",
    "random_replacena(df, 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of the address type (ADDRTYPE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block           144784\n",
       "Intersection     71773\n",
       "Alley              874\n",
       "Name: ADDRTYPE, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ADDRTYPE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the missing values with random values selected according to <font color=\"blue\"> roulette wheel selection </font>. To do this, define a function for calculating the probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_probs(data_frame, col):\n",
    "    \"\"\"\n",
    "    Find the probability distribution of data_frame.col\n",
    "    \"\"\"\n",
    "    counts = data_frame[col].value_counts().values\n",
    "    total = sum(counts)\n",
    "    probs = [float(x)/total for x in counts]\n",
    "    return probs\n",
    "\n",
    "\n",
    "def roulette_wheel_replacena(data_frame, col, show=False):\n",
    "    probs = find_probs(data_frame, col)\n",
    "    if show:\n",
    "        print(\"Probability distribution BEFORE applying roulette wheel:\")\n",
    "        print(probs)\n",
    "    values = data_frame[col].value_counts().index.values.tolist()\n",
    "    # Replace missing values using roulette wheel\n",
    "    data_frame[col] = data_frame[col].apply(lambda x: np.random.choice(values, p=probs) if (pd.isna(x)) else x)\n",
    "    # Check if there is no missing value\n",
    "    if show:\n",
    "        print(\"\")\n",
    "        print(\"Probability distribution AFTER applying roulette wheel:\")\n",
    "        print(find_probs(data_frame, col)) \n",
    "        print(\"\")\n",
    "    if data_frame[col].isna().sum() != 0:\n",
    "        print('Error!')\n",
    "    else:\n",
    "        print('Successful!')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.6658848094337974, 0.33009552455721586, 0.004019666008986759]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.6659175284770488, 0.3300714922018784, 0.00401097932107279]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'ADDRTYPE', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of location (LOCATION)**  \n",
    "\n",
    "This is a bit complicated.  \n",
    "- The attribute `LOCATION` provides a description of the general location at which the collision occured.  \n",
    "- Most of the data entries are of the form: <font color=\"blue\"> Street A BETWEEN Street B and Street C </font>. \n",
    "- In reality, some streets are more prone to accident than others. For instance, a main busy road in the city is more likely to have accidents compared to a quiet road in a quiet neighborhood. \n",
    "- Furthermore, the _specific location_ along the street is usually of a secondary importance. This is confirmed by the data from the `value_counts` since there is no dominantly frequent values.  \n",
    "- However, when the streets are considered as a whole _without partitioning the street_ as in the data, some streets appear to have significantly more accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BATTERY ST TUNNEL NB BETWEEN ALASKAN WY VI NB AND AURORA AVE N    298\n",
       "N NORTHGATE WAY BETWEEN MERIDIAN AVE N AND CORLISS AVE N          296\n",
       "BATTERY ST TUNNEL SB BETWEEN AURORA AVE N AND ALASKAN WY VI SB    291\n",
       "AURORA AVE N BETWEEN N 117TH PL AND N 125TH ST                    282\n",
       "6TH AVE AND JAMES ST                                              276\n",
       "                                                                 ... \n",
       "24TH AVE NE AND NE 60TH ST                                          1\n",
       "47TH AVE S BETWEEN S ADAMS ST AND S GENESEE ST                      1\n",
       "47TH AVE S AND S CLOVERDALE ST                                      1\n",
       "8TH AVE S BETWEEN S GARDEN ST AND S OTHELLO ST                      1\n",
       "WALNUT AVE SW BETWEEN SW STEVENS ST AND SW WINTHROP ST              1\n",
       "Name: LOCATION, Length: 25187, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LOCATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is no dominantly frequent location. Now, remove the street partition and <font color=\"blue\"> a street from its beginning to its end is considered as a _single entry_ </font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LOCATION'] = df['LOCATION'].apply(lambda x: (str(x).split('BETWEEN')[0]).strip() if \"BETWEEN\" in str(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAINIER AVE S           5712\n",
       "AURORA AVE N            3896\n",
       "1ST AVE S               1600\n",
       "LAKE CITY WAY NE        1553\n",
       "1ST AVE                 1549\n",
       "4TH AVE S               1413\n",
       "DELRIDGE WAY SW         1383\n",
       "EAST MARGINAL WAY S     1375\n",
       "GREENWOOD AVE N         1251\n",
       "NE 45TH ST              1175\n",
       "CALIFORNIA AVE SW       1113\n",
       "15TH AVE NW             1037\n",
       "ROOSEVELT WAY NE        1037\n",
       "35TH AVE SW             1020\n",
       "M L KING JR ER WAY S     993\n",
       "15TH AVE NE              980\n",
       "DENNY WAY                925\n",
       "E MADISON ST             913\n",
       "4TH AVE                  869\n",
       "M L KING JR WR WAY S     863\n",
       "Name: LOCATION, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LOCATION.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eureka! Some streets appear to have significantly more accidents compared to other streets. Those streets are among the 10 busiest streets in the Seattle city according to [this website](#https://mynorthwest.com/gallery/seattles-10-busiest-streets/). This pattern was not clearly apparent before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "# Now replace the missing values\n",
    "roulette_wheel_replacena(df, 'LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of the collision type (COLLISIONTYPE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parked Car    48451\n",
       "Angles        35460\n",
       "Rear Ended    34622\n",
       "Other         24524\n",
       "Sideswipe     18853\n",
       "Left Turn     14080\n",
       "Pedestrian     7653\n",
       "Cycles         5909\n",
       "Right Turn     3007\n",
       "Head On        2181\n",
       "Name: COLLISIONTYPE, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.COLLISIONTYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.24879839786381844, 0.18208893909828489, 0.17778576563623294, 0.12593201191332032, 0.0968111327924412, 0.07230153024545548, 0.03929855191537435, 0.03034302146451679, 0.015441100955119648, 0.011199548115435966]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.24859027868845046, 0.18253799577648852, 0.1777582831018843, 0.12624410449347254, 0.09651673351632202, 0.07194891992963828, 0.03916922534287769, 0.03042375295623194, 0.015537457663141045, 0.011273248531493196]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'COLLISIONTYPE', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of junction type (JUNCTIONTYPE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mid-Block (not related to intersection)              101523\n",
       "At Intersection (intersection related)                69067\n",
       "Mid-Block (but intersection related)                  24392\n",
       "Driveway Junction                                     11493\n",
       "At Intersection (but not related to intersection)      2495\n",
       "Ramp Junction                                           190\n",
       "Unknown                                                  21\n",
       "Name: JUNCTIONTYPE, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.JUNCTIONTYPE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use roulette wheel to replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.48533566624119784, 0.33017817105760083, 0.11660714883282898, 0.05494284853786912, 0.011927469512049373, 0.0009083042914987499, 0.00010039152695512498]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.4854325029505795, 0.3301574094590378, 0.11646310306001094, 0.05492825909027191, 0.012005806197799614, 0.0009179580633345844, 9.496117896564667e-05]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'JUNCTIONTYPE', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of whether the driver was under the influence of alcohol (UNDERINFL)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    103454\n",
       "0     81676\n",
       "Y      5399\n",
       "1      4230\n",
       "Name: UNDERINFL, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.UNDERINFL.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data source, the attribute UNDERINFL is binary which has two value: \"Y\" to indicate that the driver was under the influence of alcohol and \"N\" for negating that. \n",
    "It appears that the data entries are not consistent. <font color=\"red\"> We need to convert \"Y\" to 1 and \"N\" to 0 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    185130\n",
       "1      9629\n",
       "Name: UNDERINFL, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['UNDERINFL'] = df['UNDERINFL'].replace(to_replace={\"N\": \"0\", \"Y\":\"1\"})\n",
    "# Check \n",
    "df.UNDERINFL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.9505594093212637, 0.04944059067873628]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.95048452811077, 0.04951547188923005]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'UNDERINFL', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of weather (WEATHER)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clear                       114342\n",
       "Raining                      34019\n",
       "Overcast                     28503\n",
       "Unknown                      15131\n",
       "Snowing                        919\n",
       "Other                          851\n",
       "Fog/Smog/Smoke                 577\n",
       "Sleet/Hail/Freezing Rain       116\n",
       "Blowing Sand/Dirt               56\n",
       "Severe Crosswind                26\n",
       "Partly Cloudy                    9\n",
       "Blowing Snow                     1\n",
       "Name: WEATHER, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.WEATHER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.5877255204317656, 0.17485993317913132, 0.14650732459521973, 0.07777435106656387, 0.004723721408378309, 0.00437419686455924, 0.0029658185556412234, 0.0005962477512207659, 0.00028784374196864557, 0.00013364173734258544, 4.6260601387818045e-05, 5.140066820868671e-06]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.5873168040589121, 0.1751852873480056, 0.14682807052450225, 0.0775787612540302, 0.00464857580841356, 0.004426999724160385, 0.0029483185088381727, 0.000574289034697006, 0.0003120153023156962, 0.00013113686619065491, 4.5219609031260315e-05, 4.521960903126032e-06]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'WEATHER', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of road condition (ROADCOND)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dry               128150\n",
       "Wet                48710\n",
       "Unknown            15129\n",
       "Ice                 1231\n",
       "Snow/Slush          1014\n",
       "Other                136\n",
       "Standing Water       119\n",
       "Sand/Mud/Dirt         77\n",
       "Oil                   64\n",
       "Name: ROADCOND, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ROADCOND.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.658428813646406, 0.25026974258850126, 0.07773210707496275, 0.006324821456096182, 0.005209885423624313, 0.0006987617530699276, 0.0006114165339361866, 0.00039562246313517955, 0.00032882906026820123]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.658569342009469, 0.2501187014737071, 0.07757423929312707, 0.006466404091470225, 0.005236430725819944, 0.000723513744500165, 0.0006104647219220143, 0.0003753227549594606, 0.0003255811850250743]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "roulette_wheel_replacena(df, 'ROADCOND', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values of light condition (LIGHTCOND)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Daylight                    119148\n",
       "Dark - Street Lights On      50048\n",
       "Unknown                      13520\n",
       "Dusk                          6074\n",
       "Dawn                          2599\n",
       "Dark - No Street Lights       1573\n",
       "Dark - Street Lights Off      1236\n",
       "Other                          244\n",
       "Dark - Unknown Lighting         20\n",
       "Name: LIGHTCOND, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LIGHTCOND.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there are 6% of the accidents occurred in <font color=\"red\"> unknown road condition </font>. Intuititively, we believe that the road condition has to be related to the severity of the collision. Therefore, it is imperative to predict these <font color=\"red\"> unknown </font>. For this, we propose two solutions:\n",
    "\n",
    "- First, we can impute the value of the unknowns based on a model trained on the available data.\n",
    "- Second we can impute the value of the unknowns using our conventional roulette wheel selection which preserve the probability distribution of `LIGHTCOND`.\n",
    "\n",
    "Due to its simplicity, we chose the second method. However, the first approach should be preferred in general since it makes informative decision based on the other features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution BEFORE applying roulette wheel:\n",
      "[0.6584872500580297, 0.2765969205601795, 0.03356876789247383, 0.014363718760707852, 0.008693393463098673, 0.006830918194780648, 0.001348498413856374, 0.00011053265687347326]\n",
      "\n",
      "Probability distribution AFTER applying roulette wheel:\n",
      "[0.6578367843431626, 0.27734542807142887, 0.033516774213970146, 0.014370791750134528, 0.008650511207680098, 0.006868858611848442, 0.001297802779197171, 0.00011304902257815078]\n",
      "\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "# First convert \"Unknown\" to nan\n",
    "df['LIGHTCOND'] = df['LIGHTCOND'].replace(to_replace=\"Unknown\", value=np.nan)\n",
    "# Replace the missing values using the roulette wheel selection\n",
    "roulette_wheel_replacena(df, 'LIGHTCOND', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> **Great! All missing values have been handled! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do one last check that the data is free of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:  X\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  Y\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  STATUS\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  ADDRTYPE\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  LOCATION\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  SEVERITYCODE\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  COLLISIONTYPE\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  PERSONCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  PEDCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  PEDCYLCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  VEHCOUNT\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  INJURIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  SERIOUSINJURIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  FATALITIES\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  JUNCTIONTYPE\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  UNDERINFL\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  WEATHER\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  ROADCOND\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  LIGHTCOND\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  SEGLANEKEY\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n",
      "Column Name:  CROSSWALKKEY\n",
      "Missing Value?  False  Percentage:  100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayna(df, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we normalize the data and transform it into a format that is more convenient for the machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                  float64\n",
       "Y                  float64\n",
       "STATUS              object\n",
       "ADDRTYPE            object\n",
       "LOCATION            object\n",
       "SEVERITYCODE        object\n",
       "COLLISIONTYPE       object\n",
       "PERSONCOUNT          int64\n",
       "PEDCOUNT             int64\n",
       "PEDCYLCOUNT          int64\n",
       "VEHCOUNT             int64\n",
       "INJURIES             int64\n",
       "SERIOUSINJURIES      int64\n",
       "FATALITIES           int64\n",
       "JUNCTIONTYPE        object\n",
       "UNDERINFL           object\n",
       "WEATHER             object\n",
       "ROADCOND            object\n",
       "LIGHTCOND           object\n",
       "SEGLANEKEY           int64\n",
       "CROSSWALKKEY         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let us check the data types of the features and correct it if necessary\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methodology <a class=\"anchor\" id=\"method\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
